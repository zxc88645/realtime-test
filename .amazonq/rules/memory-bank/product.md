# GPT 即時延遲實驗室

## 專案目的
一個 Node.js 示範專案，比較連接 OpenAI Realtime API 時 WebRTC 資料通道與 WebSocket 傳輸的延遲差異。應用程式提供並排效能分析，協助開發者了解本地環境中的傳輸差異。

## 主要功能
- **雙重傳輸比較**：同時建立 WebSocket 和 WebRTC 連線至 OpenAI Realtime API
- **即時延遲測量**：追蹤從提示提交到 GPT 回應完成的往返時間
- **WebSocket 代理**：橋接瀏覽器 WebSocket 流量至 OpenAI 即時端點
- **短效金鑰生成**：透過 REST 端點簽發短期 WebRTC 金鑰
- **互動式儀表板**：基於瀏覽器的介面，用於發送提示和查看比較結果
- **效能分析**：視覺化比較連線時間、抖動和往返效能

## 目標使用者
- **開發者**：評估即時 AI 應用程式的傳輸選項
- **效能工程師**：分析不同連線方法的延遲特性
- **AI 應用程式架構師**：對傳輸層選擇做出明智決策
- **研究人員**：研究 AI 服務的即時通訊效能

## 使用案例
- 為 AI 聊天應用程式基準測試 WebSocket 與 WebRTC 效能
- 評估網路條件對不同傳輸協定的影響
- 測試 OpenAI Realtime API 整合方法
- 在教育情境中展示傳輸層差異
- 以最佳傳輸選擇原型化即時 AI 應用程式